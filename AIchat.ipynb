{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "# install needed libraries into your venv (run only once or when missing)\n",
    "!pip install sentence-transformers faiss-cpu numpy python-dotenv openai\n",
    "\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "print(\"Libraries imported.\")\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"Data/multi_country_real_colleges_faq_with_meta.csv\"\n",
    "faq_df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Rows:\", len(faq_df))\n",
    "faq_df.head()\n"
   ],
   "id": "da2c319aa07d37b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "docs = []\n",
    "metadata = []\n",
    "\n",
    "for _, row in faq_df.iterrows():\n",
    "    college = row[\"college_name\"]\n",
    "    country = row[\"country\"]\n",
    "    ctype = row[\"type\"]\n",
    "    q = str(row[\"question\"])\n",
    "    a = str(row[\"answer\"])\n",
    "\n",
    "    # full text stored for embeddings\n",
    "    text = f\"College: {college}\\nCountry: {country}\\nType: {ctype}\\nQ: {q}\\nA: {a}\"\n",
    "    docs.append(text)\n",
    "\n",
    "    # metadata stored separately\n",
    "    metadata.append({\n",
    "        \"college_name\": college,\n",
    "        \"country\": country,\n",
    "        \"type\": ctype\n",
    "    })\n",
    "\n",
    "print(\"Docs loaded:\", len(docs))\n"
   ],
   "id": "566741963f3c73b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Loading Sentence-BERT model...\")\n",
    "embed_model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "print(\"Encoding documents...\")\n",
    "embeddings = embed_model.encode(docs, show_progress_bar=True, convert_to_numpy=True)\n",
    "\n",
    "dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(embeddings)\n",
    "\n",
    "print(\"Index size (vectors):\", index.ntotal)\n"
   ],
   "id": "645817554c6eeec1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from groq import Groq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "K = 3  # top-k docs\n",
    "\n",
    "def retrieve_context(query, k=K):\n",
    "    q_emb = embed_model.encode([query], convert_to_numpy=True)\n",
    "    distances, indices = index.search(q_emb, k)\n",
    "    return [docs[i] for i in indices[0]]\n",
    "\n",
    "def generate_answer(query, k=K):\n",
    "    context = \"\\n\\n\".join(retrieve_context(query, k))\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an enquiry bot for Galgotias University.\n",
    "Use ONLY the information in the context to answer the question.\n",
    "If the answer is not in the context, clearly say you don't know.\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION:\n",
    "{query}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3.1-8b-instant\",   # âœ… valid, supported Groq model\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def ask(q):\n",
    "    print(\"Q:\", q)\n",
    "    print(\"\\nA:\", generate_answer(q))\n"
   ],
   "id": "c9d7feba5c268ed8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ask(\"What is the admission process for B.Tech?\")\n",
    "ask(\"Is hostel facility available for students?\")\n"
   ],
   "id": "ba361ef3c79765c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ask(\"What is the admission process for B.Tech?\")\n",
    "ask(\"Is hostel facility available for students?\")\n",
    "ask(\"What is the annual fee for B.Tech CSE?\")\n",
    "ask(\"Does the university provide transport facilities?\")\n"
   ],
   "id": "5848bae0d16e9bd8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "while True:\n",
    "    q = input(\"\\nYou: \")\n",
    "    if q.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "        print(\"Bot: Bye ðŸ‘‹\")\n",
    "        break\n",
    "    print(\"Bot:\", generate_answer(q))\n"
   ],
   "id": "cf65adf2c8ffa44f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
